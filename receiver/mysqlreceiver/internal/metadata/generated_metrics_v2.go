// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/model/pdata"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for mysqlreceiver metrics.
type MetricsSettings struct {
	MysqlBufferPoolOperations MetricSettings `mapstructure:"mysql.buffer_pool_operations"`
	MysqlBufferPoolPages      MetricSettings `mapstructure:"mysql.buffer_pool_pages"`
	MysqlBufferPoolSize       MetricSettings `mapstructure:"mysql.buffer_pool_size"`
	MysqlCommands             MetricSettings `mapstructure:"mysql.commands"`
	MysqlDoubleWrites         MetricSettings `mapstructure:"mysql.double_writes"`
	MysqlHandlers             MetricSettings `mapstructure:"mysql.handlers"`
	MysqlLocks                MetricSettings `mapstructure:"mysql.locks"`
	MysqlLogOperations        MetricSettings `mapstructure:"mysql.log_operations"`
	MysqlOperations           MetricSettings `mapstructure:"mysql.operations"`
	MysqlPageOperations       MetricSettings `mapstructure:"mysql.page_operations"`
	MysqlRowLocks             MetricSettings `mapstructure:"mysql.row_locks"`
	MysqlRowOperations        MetricSettings `mapstructure:"mysql.row_operations"`
	MysqlSorts                MetricSettings `mapstructure:"mysql.sorts"`
	MysqlThreads              MetricSettings `mapstructure:"mysql.threads"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		MysqlBufferPoolOperations: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolPages: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolSize: MetricSettings{
			Enabled: true,
		},
		MysqlCommands: MetricSettings{
			Enabled: true,
		},
		MysqlDoubleWrites: MetricSettings{
			Enabled: true,
		},
		MysqlHandlers: MetricSettings{
			Enabled: true,
		},
		MysqlLocks: MetricSettings{
			Enabled: true,
		},
		MysqlLogOperations: MetricSettings{
			Enabled: true,
		},
		MysqlOperations: MetricSettings{
			Enabled: true,
		},
		MysqlPageOperations: MetricSettings{
			Enabled: true,
		},
		MysqlRowLocks: MetricSettings{
			Enabled: true,
		},
		MysqlRowOperations: MetricSettings{
			Enabled: true,
		},
		MysqlSorts: MetricSettings{
			Enabled: true,
		},
		MysqlThreads: MetricSettings{
			Enabled: true,
		},
	}
}

type metricMysqlBufferPoolOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool_operations metric with initial data.
func (m *metricMysqlBufferPoolOperations) init() {
	m.data.SetName("mysql.buffer_pool_operations")
	m.data.SetDescription("The number of operations on the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, bufferPoolOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.BufferPoolOperations, pdata.NewAttributeValueString(bufferPoolOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolOperations(settings MetricSettings) metricMysqlBufferPoolOperations {
	m := metricMysqlBufferPoolOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolPages struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool_pages metric with initial data.
func (m *metricMysqlBufferPoolPages) init() {
	m.data.SetName("mysql.buffer_pool_pages")
	m.data.SetDescription("The number of pages in the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolPages) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val float64, bufferPoolPagesAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleVal(val)
	dp.Attributes().Insert(A.BufferPoolPages, pdata.NewAttributeValueString(bufferPoolPagesAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolPages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolPages) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolPages(settings MetricSettings) metricMysqlBufferPoolPages {
	m := metricMysqlBufferPoolPages{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolSize struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool_size metric with initial data.
func (m *metricMysqlBufferPoolSize) init() {
	m.data.SetName("mysql.buffer_pool_size")
	m.data.SetDescription("The number of bytes in the InnoDB buffer pool.")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolSize) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val float64, bufferPoolSizeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleVal(val)
	dp.Attributes().Insert(A.BufferPoolSize, pdata.NewAttributeValueString(bufferPoolSizeAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolSize) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolSize(settings MetricSettings) metricMysqlBufferPoolSize {
	m := metricMysqlBufferPoolSize{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlCommands struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.commands metric with initial data.
func (m *metricMysqlCommands) init() {
	m.data.SetName("mysql.commands")
	m.data.SetDescription("The number of times each type of command has been executed.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlCommands) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, commandAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Command, pdata.NewAttributeValueString(commandAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlCommands) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlCommands) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlCommands(settings MetricSettings) metricMysqlCommands {
	m := metricMysqlCommands{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlDoubleWrites struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.double_writes metric with initial data.
func (m *metricMysqlDoubleWrites) init() {
	m.data.SetName("mysql.double_writes")
	m.data.SetDescription("The number of writes to the InnoDB doublewrite buffer.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlDoubleWrites) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, doubleWritesAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.DoubleWrites, pdata.NewAttributeValueString(doubleWritesAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlDoubleWrites) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlDoubleWrites) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlDoubleWrites(settings MetricSettings) metricMysqlDoubleWrites {
	m := metricMysqlDoubleWrites{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlHandlers struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.handlers metric with initial data.
func (m *metricMysqlHandlers) init() {
	m.data.SetName("mysql.handlers")
	m.data.SetDescription("The number of requests to various MySQL handlers.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlHandlers) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, handlerAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Handler, pdata.NewAttributeValueString(handlerAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlHandlers) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlHandlers) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlHandlers(settings MetricSettings) metricMysqlHandlers {
	m := metricMysqlHandlers{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlLocks struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.locks metric with initial data.
func (m *metricMysqlLocks) init() {
	m.data.SetName("mysql.locks")
	m.data.SetDescription("The number of MySQL locks.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlLocks) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, locksAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Locks, pdata.NewAttributeValueString(locksAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlLocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlLocks) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlLocks(settings MetricSettings) metricMysqlLocks {
	m := metricMysqlLocks{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlLogOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.log_operations metric with initial data.
func (m *metricMysqlLogOperations) init() {
	m.data.SetName("mysql.log_operations")
	m.data.SetDescription("The number of InndoDB log operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlLogOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, logOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.LogOperations, pdata.NewAttributeValueString(logOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlLogOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlLogOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlLogOperations(settings MetricSettings) metricMysqlLogOperations {
	m := metricMysqlLogOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.operations metric with initial data.
func (m *metricMysqlOperations) init() {
	m.data.SetName("mysql.operations")
	m.data.SetDescription("The number of InndoDB operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, operationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Operations, pdata.NewAttributeValueString(operationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlOperations(settings MetricSettings) metricMysqlOperations {
	m := metricMysqlOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlPageOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.page_operations metric with initial data.
func (m *metricMysqlPageOperations) init() {
	m.data.SetName("mysql.page_operations")
	m.data.SetDescription("The number of InndoDB page operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlPageOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, pageOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.PageOperations, pdata.NewAttributeValueString(pageOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlPageOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlPageOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlPageOperations(settings MetricSettings) metricMysqlPageOperations {
	m := metricMysqlPageOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlRowLocks struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.row_locks metric with initial data.
func (m *metricMysqlRowLocks) init() {
	m.data.SetName("mysql.row_locks")
	m.data.SetDescription("The number of InndoDB row locks.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlRowLocks) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, rowLocksAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.RowLocks, pdata.NewAttributeValueString(rowLocksAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlRowLocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlRowLocks) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlRowLocks(settings MetricSettings) metricMysqlRowLocks {
	m := metricMysqlRowLocks{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlRowOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.row_operations metric with initial data.
func (m *metricMysqlRowOperations) init() {
	m.data.SetName("mysql.row_operations")
	m.data.SetDescription("The number of InndoDB row operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlRowOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, rowOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.RowOperations, pdata.NewAttributeValueString(rowOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlRowOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlRowOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlRowOperations(settings MetricSettings) metricMysqlRowOperations {
	m := metricMysqlRowOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSorts struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.sorts metric with initial data.
func (m *metricMysqlSorts) init() {
	m.data.SetName("mysql.sorts")
	m.data.SetDescription("The number of MySQL sorts.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlSorts) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, sortsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Sorts, pdata.NewAttributeValueString(sortsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSorts) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSorts) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSorts(settings MetricSettings) metricMysqlSorts {
	m := metricMysqlSorts{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlThreads struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.threads metric with initial data.
func (m *metricMysqlThreads) init() {
	m.data.SetName("mysql.threads")
	m.data.SetDescription("The state of MySQL threads.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlThreads) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val float64, threadsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleVal(val)
	dp.Attributes().Insert(A.Threads, pdata.NewAttributeValueString(threadsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlThreads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlThreads) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlThreads(settings MetricSettings) metricMysqlThreads {
	m := metricMysqlThreads{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                       pdata.Timestamp
	metricMysqlBufferPoolOperations metricMysqlBufferPoolOperations
	metricMysqlBufferPoolPages      metricMysqlBufferPoolPages
	metricMysqlBufferPoolSize       metricMysqlBufferPoolSize
	metricMysqlCommands             metricMysqlCommands
	metricMysqlDoubleWrites         metricMysqlDoubleWrites
	metricMysqlHandlers             metricMysqlHandlers
	metricMysqlLocks                metricMysqlLocks
	metricMysqlLogOperations        metricMysqlLogOperations
	metricMysqlOperations           metricMysqlOperations
	metricMysqlPageOperations       metricMysqlPageOperations
	metricMysqlRowLocks             metricMysqlRowLocks
	metricMysqlRowOperations        metricMysqlRowOperations
	metricMysqlSorts                metricMysqlSorts
	metricMysqlThreads              metricMysqlThreads
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pdata.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                       pdata.NewTimestampFromTime(time.Now()),
		metricMysqlBufferPoolOperations: newMetricMysqlBufferPoolOperations(settings.MysqlBufferPoolOperations),
		metricMysqlBufferPoolPages:      newMetricMysqlBufferPoolPages(settings.MysqlBufferPoolPages),
		metricMysqlBufferPoolSize:       newMetricMysqlBufferPoolSize(settings.MysqlBufferPoolSize),
		metricMysqlCommands:             newMetricMysqlCommands(settings.MysqlCommands),
		metricMysqlDoubleWrites:         newMetricMysqlDoubleWrites(settings.MysqlDoubleWrites),
		metricMysqlHandlers:             newMetricMysqlHandlers(settings.MysqlHandlers),
		metricMysqlLocks:                newMetricMysqlLocks(settings.MysqlLocks),
		metricMysqlLogOperations:        newMetricMysqlLogOperations(settings.MysqlLogOperations),
		metricMysqlOperations:           newMetricMysqlOperations(settings.MysqlOperations),
		metricMysqlPageOperations:       newMetricMysqlPageOperations(settings.MysqlPageOperations),
		metricMysqlRowLocks:             newMetricMysqlRowLocks(settings.MysqlRowLocks),
		metricMysqlRowOperations:        newMetricMysqlRowOperations(settings.MysqlRowOperations),
		metricMysqlSorts:                newMetricMysqlSorts(settings.MysqlSorts),
		metricMysqlThreads:              newMetricMysqlThreads(settings.MysqlThreads),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// Emit appends generated metrics to a pdata.MetricsSlice and updates the internal state to be ready for recording
// another set of data points. This function will be doing all transformations required to produce metric representation
// defined in metadata and user settings, e.g. delta/cumulative translation.
func (mb *MetricsBuilder) Emit(metrics pdata.MetricSlice) {
	mb.metricMysqlBufferPoolOperations.emit(metrics)
	mb.metricMysqlBufferPoolPages.emit(metrics)
	mb.metricMysqlBufferPoolSize.emit(metrics)
	mb.metricMysqlCommands.emit(metrics)
	mb.metricMysqlDoubleWrites.emit(metrics)
	mb.metricMysqlHandlers.emit(metrics)
	mb.metricMysqlLocks.emit(metrics)
	mb.metricMysqlLogOperations.emit(metrics)
	mb.metricMysqlOperations.emit(metrics)
	mb.metricMysqlPageOperations.emit(metrics)
	mb.metricMysqlRowLocks.emit(metrics)
	mb.metricMysqlRowOperations.emit(metrics)
	mb.metricMysqlSorts.emit(metrics)
	mb.metricMysqlThreads.emit(metrics)
}

// RecordMysqlBufferPoolOperationsDataPoint adds a data point to mysql.buffer_pool_operations metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolOperationsDataPoint(ts pdata.Timestamp, val int64, bufferPoolOperationsAttributeValue string) {
	mb.metricMysqlBufferPoolOperations.recordDataPoint(mb.startTime, ts, val, bufferPoolOperationsAttributeValue)
}

// RecordMysqlBufferPoolPagesDataPoint adds a data point to mysql.buffer_pool_pages metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolPagesDataPoint(ts pdata.Timestamp, val float64, bufferPoolPagesAttributeValue string) {
	mb.metricMysqlBufferPoolPages.recordDataPoint(mb.startTime, ts, val, bufferPoolPagesAttributeValue)
}

// RecordMysqlBufferPoolSizeDataPoint adds a data point to mysql.buffer_pool_size metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolSizeDataPoint(ts pdata.Timestamp, val float64, bufferPoolSizeAttributeValue string) {
	mb.metricMysqlBufferPoolSize.recordDataPoint(mb.startTime, ts, val, bufferPoolSizeAttributeValue)
}

// RecordMysqlCommandsDataPoint adds a data point to mysql.commands metric.
func (mb *MetricsBuilder) RecordMysqlCommandsDataPoint(ts pdata.Timestamp, val int64, commandAttributeValue string) {
	mb.metricMysqlCommands.recordDataPoint(mb.startTime, ts, val, commandAttributeValue)
}

// RecordMysqlDoubleWritesDataPoint adds a data point to mysql.double_writes metric.
func (mb *MetricsBuilder) RecordMysqlDoubleWritesDataPoint(ts pdata.Timestamp, val int64, doubleWritesAttributeValue string) {
	mb.metricMysqlDoubleWrites.recordDataPoint(mb.startTime, ts, val, doubleWritesAttributeValue)
}

// RecordMysqlHandlersDataPoint adds a data point to mysql.handlers metric.
func (mb *MetricsBuilder) RecordMysqlHandlersDataPoint(ts pdata.Timestamp, val int64, handlerAttributeValue string) {
	mb.metricMysqlHandlers.recordDataPoint(mb.startTime, ts, val, handlerAttributeValue)
}

// RecordMysqlLocksDataPoint adds a data point to mysql.locks metric.
func (mb *MetricsBuilder) RecordMysqlLocksDataPoint(ts pdata.Timestamp, val int64, locksAttributeValue string) {
	mb.metricMysqlLocks.recordDataPoint(mb.startTime, ts, val, locksAttributeValue)
}

// RecordMysqlLogOperationsDataPoint adds a data point to mysql.log_operations metric.
func (mb *MetricsBuilder) RecordMysqlLogOperationsDataPoint(ts pdata.Timestamp, val int64, logOperationsAttributeValue string) {
	mb.metricMysqlLogOperations.recordDataPoint(mb.startTime, ts, val, logOperationsAttributeValue)
}

// RecordMysqlOperationsDataPoint adds a data point to mysql.operations metric.
func (mb *MetricsBuilder) RecordMysqlOperationsDataPoint(ts pdata.Timestamp, val int64, operationsAttributeValue string) {
	mb.metricMysqlOperations.recordDataPoint(mb.startTime, ts, val, operationsAttributeValue)
}

// RecordMysqlPageOperationsDataPoint adds a data point to mysql.page_operations metric.
func (mb *MetricsBuilder) RecordMysqlPageOperationsDataPoint(ts pdata.Timestamp, val int64, pageOperationsAttributeValue string) {
	mb.metricMysqlPageOperations.recordDataPoint(mb.startTime, ts, val, pageOperationsAttributeValue)
}

// RecordMysqlRowLocksDataPoint adds a data point to mysql.row_locks metric.
func (mb *MetricsBuilder) RecordMysqlRowLocksDataPoint(ts pdata.Timestamp, val int64, rowLocksAttributeValue string) {
	mb.metricMysqlRowLocks.recordDataPoint(mb.startTime, ts, val, rowLocksAttributeValue)
}

// RecordMysqlRowOperationsDataPoint adds a data point to mysql.row_operations metric.
func (mb *MetricsBuilder) RecordMysqlRowOperationsDataPoint(ts pdata.Timestamp, val int64, rowOperationsAttributeValue string) {
	mb.metricMysqlRowOperations.recordDataPoint(mb.startTime, ts, val, rowOperationsAttributeValue)
}

// RecordMysqlSortsDataPoint adds a data point to mysql.sorts metric.
func (mb *MetricsBuilder) RecordMysqlSortsDataPoint(ts pdata.Timestamp, val int64, sortsAttributeValue string) {
	mb.metricMysqlSorts.recordDataPoint(mb.startTime, ts, val, sortsAttributeValue)
}

// RecordMysqlThreadsDataPoint adds a data point to mysql.threads metric.
func (mb *MetricsBuilder) RecordMysqlThreadsDataPoint(ts pdata.Timestamp, val float64, threadsAttributeValue string) {
	mb.metricMysqlThreads.recordDataPoint(mb.startTime, ts, val, threadsAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pdata.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}

// Attributes contains the possible metric attributes that can be used.
var Attributes = struct {
	// BufferPoolOperations (The buffer pool operations types.)
	BufferPoolOperations string
	// BufferPoolPages (The buffer pool pages types.)
	BufferPoolPages string
	// BufferPoolSize (The buffer pool size types.)
	BufferPoolSize string
	// Command (The command types.)
	Command string
	// DoubleWrites (The doublewrite types.)
	DoubleWrites string
	// Handler (The handler types.)
	Handler string
	// Locks (The table locks type.)
	Locks string
	// LogOperations (The log operation types.)
	LogOperations string
	// Operations (The operation types.)
	Operations string
	// PageOperations (The page operation types.)
	PageOperations string
	// RowLocks (The row lock type.)
	RowLocks string
	// RowOperations (The row operation type.)
	RowOperations string
	// Sorts (The sort count type.)
	Sorts string
	// Threads (The thread count type.)
	Threads string
}{
	"operation",
	"kind",
	"kind",
	"command",
	"kind",
	"kind",
	"kind",
	"operation",
	"operation",
	"operation",
	"kind",
	"operation",
	"kind",
	"kind",
}

// A is an alias for Attributes.
var A = Attributes

// AttributeBufferPoolOperations are the possible values that the attribute "buffer_pool_operations" can have.
var AttributeBufferPoolOperations = struct {
	ReadAheadRnd     string
	ReadAhead        string
	ReadAheadEvicted string
	ReadRequests     string
	Reads            string
	WaitFree         string
	WriteRequests    string
}{
	"read_ahead_rnd",
	"read_ahead",
	"read_ahead_evicted",
	"read_requests",
	"reads",
	"wait_free",
	"write_requests",
}

// AttributeBufferPoolPages are the possible values that the attribute "buffer_pool_pages" can have.
var AttributeBufferPoolPages = struct {
	Data    string
	Dirty   string
	Flushed string
	Free    string
	Misc    string
	Total   string
}{
	"data",
	"dirty",
	"flushed",
	"free",
	"misc",
	"total",
}

// AttributeBufferPoolSize are the possible values that the attribute "buffer_pool_size" can have.
var AttributeBufferPoolSize = struct {
	Data  string
	Dirty string
	Total string
}{
	"data",
	"dirty",
	"total",
}

// AttributeCommand are the possible values that the attribute "command" can have.
var AttributeCommand = struct {
	Execute      string
	Close        string
	Fetch        string
	Prepare      string
	Reset        string
	SendLongData string
}{
	"execute",
	"close",
	"fetch",
	"prepare",
	"reset",
	"send_long_data",
}

// AttributeDoubleWrites are the possible values that the attribute "double_writes" can have.
var AttributeDoubleWrites = struct {
	PagesWritten string
	Writes       string
}{
	"pages_written",
	"writes",
}

// AttributeHandler are the possible values that the attribute "handler" can have.
var AttributeHandler = struct {
	Commit            string
	Delete            string
	Discover          string
	ExternalLock      string
	MrrInit           string
	Prepare           string
	ReadFirst         string
	ReadKey           string
	ReadLast          string
	ReadNext          string
	ReadPrev          string
	ReadRnd           string
	ReadRndNext       string
	Rollback          string
	Savepoint         string
	SavepointRollback string
	Update            string
	Write             string
}{
	"commit",
	"delete",
	"discover",
	"external_lock",
	"mrr_init",
	"prepare",
	"read_first",
	"read_key",
	"read_last",
	"read_next",
	"read_prev",
	"read_rnd",
	"read_rnd_next",
	"rollback",
	"savepoint",
	"savepoint_rollback",
	"update",
	"write",
}

// AttributeLocks are the possible values that the attribute "locks" can have.
var AttributeLocks = struct {
	Immediate string
	Waited    string
}{
	"immediate",
	"waited",
}

// AttributeLogOperations are the possible values that the attribute "log_operations" can have.
var AttributeLogOperations = struct {
	Waits         string
	WriteRequests string
	Writes        string
}{
	"waits",
	"write_requests",
	"writes",
}

// AttributeOperations are the possible values that the attribute "operations" can have.
var AttributeOperations = struct {
	Fsyncs string
	Reads  string
	Writes string
}{
	"fsyncs",
	"reads",
	"writes",
}

// AttributePageOperations are the possible values that the attribute "page_operations" can have.
var AttributePageOperations = struct {
	Created string
	Read    string
	Written string
}{
	"created",
	"read",
	"written",
}

// AttributeRowLocks are the possible values that the attribute "row_locks" can have.
var AttributeRowLocks = struct {
	Waits string
	Time  string
}{
	"waits",
	"time",
}

// AttributeRowOperations are the possible values that the attribute "row_operations" can have.
var AttributeRowOperations = struct {
	Deleted  string
	Inserted string
	Read     string
	Updated  string
}{
	"deleted",
	"inserted",
	"read",
	"updated",
}

// AttributeSorts are the possible values that the attribute "sorts" can have.
var AttributeSorts = struct {
	MergePasses string
	Range       string
	Rows        string
	Scan        string
}{
	"merge_passes",
	"range",
	"rows",
	"scan",
}

// AttributeThreads are the possible values that the attribute "threads" can have.
var AttributeThreads = struct {
	Cached    string
	Connected string
	Created   string
	Running   string
}{
	"cached",
	"connected",
	"created",
	"running",
}
